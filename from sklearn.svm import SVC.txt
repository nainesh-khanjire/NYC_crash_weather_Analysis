from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.metrics import accuracy_score
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
import numpy as np

# Reduce the size of the parameter grid
#param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1], 'kernel': ['rbf', 'linear']}
param_grid = {'svc__C': [0.1], 'svc__gamma': [0.1], 'svc__kernel': ['linear']}


# Create a support vector classifier
svc = SVC()

# Create a PCA object to reduce the dimensionality of the data
pca = PCA(n_components=0.95)

# Create a logistic regression object to use as an alternative model
logreg = LogisticRegression(max_iter=100)

# Create a pipeline object to combine PCA and SVM
pipeline = Pipeline([('pca', pca), ('svc', svc)])

# Create a GridSearchCV object to search over the parameter grid using 5-fold cross-validation
grid_search = GridSearchCV(pipeline, param_grid, cv=2, scoring='accuracy', n_jobs=-1)

# Alternatively, you can use a randomized search with fewer iterations
# random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid, n_iter=10, cv=5, scoring='accuracy', n_jobs=-1)

# Fit the GridSearchCV object to the training data
grid_search.fit(X_train, y_train)

# Alternatively, you can fit the randomized search object instead
# random_search.fit(X_train, y_train)

# Use the best estimator to make predictions on the test data
y_pred = grid_search.best_estimator_.predict(X_test)

# Calculate the accuracy of the predictions
accuracy = accuracy_score(y_test, y_pred)

print("Accuracy:", accuracy)
print("Best parameters:", grid_search.best_params_)
